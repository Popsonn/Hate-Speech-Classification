{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1459bc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ffea12c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31957</th>\n",
       "      <td>31958</td>\n",
       "      <td>0</td>\n",
       "      <td>ate @user isz that youuu?ðððððð...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31958</th>\n",
       "      <td>31959</td>\n",
       "      <td>0</td>\n",
       "      <td>to see nina turner on the airwaves trying to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31959</th>\n",
       "      <td>31960</td>\n",
       "      <td>0</td>\n",
       "      <td>listening to sad songs on a monday morning otw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31960</th>\n",
       "      <td>31961</td>\n",
       "      <td>1</td>\n",
       "      <td>@user #sikh #temple vandalised in in #calgary,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31961</th>\n",
       "      <td>31962</td>\n",
       "      <td>0</td>\n",
       "      <td>thank you @user for you follow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31962 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  label                                              tweet\n",
       "0          1      0   @user when a father is dysfunctional and is s...\n",
       "1          2      0  @user @user thanks for #lyft credit i can't us...\n",
       "2          3      0                                bihday your majesty\n",
       "3          4      0  #model   i love u take with u all the time in ...\n",
       "4          5      0             factsguide: society now    #motivation\n",
       "...      ...    ...                                                ...\n",
       "31957  31958      0  ate @user isz that youuu?ðððððð...\n",
       "31958  31959      0    to see nina turner on the airwaves trying to...\n",
       "31959  31960      0  listening to sad songs on a monday morning otw...\n",
       "31960  31961      1  @user #sikh #temple vandalised in in #calgary,...\n",
       "31961  31962      0                   thank you @user for you follow  \n",
       "\n",
       "[31962 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.read_csv('train_E6oV3lV.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07263016",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id       0\n",
       "label    0\n",
       "tweet    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for null\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79fe29ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4340a25",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#note that label 1 means that the tweet is racist/sexist while label 0 means the tweet is not racist/sexist \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53acdd7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           when a father is dysfunctional and is so se...\n",
       "1            thanks for #lyft credit i can t use cause ...\n",
       "2                                      bihday your majesty\n",
       "3        #model   i love u take with u all the time in ...\n",
       "4                   factsguide  society now    #motivation\n",
       "                               ...                        \n",
       "31957    ate   isz that youuu                          ...\n",
       "31958      to see nina turner on the airwaves trying to...\n",
       "31959    listening to sad songs on a monday morning otw...\n",
       "31960      #sikh #temple vandalised in in #calgary  #ws...\n",
       "31961                         thank you   for you follow  \n",
       "Name: tweet, Length: 31962, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove special characters that are not # and a-z\n",
    "df['Text'] = df['tweet'].str.replace('[^a-zA-Z#]', ' ', regex=True)\n",
    "\n",
    "#remove user \n",
    "df['tweet']= df['Text'].str.replace('user','')\n",
    "\n",
    "df['tweet']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c477f86c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        when father dysfunctional and selfish drags hi...\n",
       "1        thanks for #lyft credit can use cause they don...\n",
       "2                                      bihday your majesty\n",
       "3                       #model love take with all the time\n",
       "4                       factsguide society now #motivation\n",
       "                               ...                        \n",
       "31957                                   ate isz that youuu\n",
       "31958    see nina turner the airwaves trying wrap herse...\n",
       "31959      listening sad songs monday morning otw work sad\n",
       "31960    #sikh #temple vandalised #calgary #wso condemn...\n",
       "31961                             thank you for you follow\n",
       "Name: tweet, Length: 31962, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove additional spaces \n",
    "df['tweet'] = df['tweet'].apply(lambda x: re.sub(r'\\s+', ' ', x))\n",
    "\n",
    "#remove words that are less than 3 in length\n",
    "df['tweet'] = df['tweet'].apply(lambda x: ' '.join([word for word in x.split() if len(word) >= 3]))\n",
    "\n",
    "#convert all words to lowercase\n",
    "df['tweet'] = df['tweet'].str.lower()\n",
    "df['tweet']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06ab5ada",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>when father dysfunctional and selfish drags hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>thanks for #lyft credit can use cause they don...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model love take with all the time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide society now #motivation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31957</th>\n",
       "      <td>31958</td>\n",
       "      <td>0</td>\n",
       "      <td>ate isz that youuu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31958</th>\n",
       "      <td>31959</td>\n",
       "      <td>0</td>\n",
       "      <td>see nina turner the airwaves trying wrap herse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31959</th>\n",
       "      <td>31960</td>\n",
       "      <td>0</td>\n",
       "      <td>listening sad songs monday morning otw work sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31960</th>\n",
       "      <td>31961</td>\n",
       "      <td>1</td>\n",
       "      <td>#sikh #temple vandalised #calgary #wso condemn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31961</th>\n",
       "      <td>31962</td>\n",
       "      <td>0</td>\n",
       "      <td>thank you for you follow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31962 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  label                                              tweet\n",
       "0          1      0  when father dysfunctional and selfish drags hi...\n",
       "1          2      0  thanks for #lyft credit can use cause they don...\n",
       "2          3      0                                bihday your majesty\n",
       "3          4      0                 #model love take with all the time\n",
       "4          5      0                 factsguide society now #motivation\n",
       "...      ...    ...                                                ...\n",
       "31957  31958      0                                 ate isz that youuu\n",
       "31958  31959      0  see nina turner the airwaves trying wrap herse...\n",
       "31959  31960      0    listening sad songs monday morning otw work sad\n",
       "31960  31961      1  #sikh #temple vandalised #calgary #wso condemn...\n",
       "31961  31962      0                           thank you for you follow\n",
       "\n",
       "[31962 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(['Text'],axis = 1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92452379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calling X and y \n",
    "X = df['tweet']\n",
    "y = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f80ae7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of training set: 22373\n",
      "The length of testing set: 9589\n"
     ]
    }
   ],
   "source": [
    "#testing and training sets \n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y, test_size = 0.3,random_state = 42)\n",
    "print ('The length of training set:',len(X_train))\n",
    "print ('The length of testing set:',len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f82270db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "# Apply stopword removal to X_train\n",
    "X_train_cleaned = X_train.apply(lambda x: ' '.join(word for word in x.split() if word.lower() not in stop_words))\n",
    "\n",
    "# Apply stopword removal to X_test\n",
    "X_test_cleaned = X_test.apply(lambda x: ' '.join(word for word in x.split() if word.lower() not in stop_words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a6a0c7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9635     summer time #summeriscoming #swimming #picofth...\n",
       "2447     dese niggas show dese otha bitches snap twitte...\n",
       "16134         boost immune system allow bodies use #energy\n",
       "18393    reading manuscript wanting stop good evening g...\n",
       "4420                                 baby says hates today\n",
       "                               ...                        \n",
       "29802    #waltdisneyreso ashamed knew alligators beach ...\n",
       "5390     invited catch stop talking much love job #reta...\n",
       "860      black professor makes assumptions entire race ...\n",
       "15795    #lgbtqhatetrumppay total #liberal trash amp #p...\n",
       "23654                    makes people relative way #africa\n",
       "Name: tweet, Length: 22373, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc5229d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12227    mom says smile captivating says happy sunday p...\n",
       "14709    days meeting sis law couney bowers first vel l...\n",
       "19319    hating conservative homophobes using tragedy w...\n",
       "4308     awee #scream #friday #acewellstucker #cynthiab...\n",
       "24055    fathersday #father #day #god #tony #smith buy ...\n",
       "                               ...                        \n",
       "20593                                #model love take time\n",
       "11682    afraid done nothing wrong salla pura barbad ka...\n",
       "10882    weeks till perform showcase #actors #performin...\n",
       "6084     real #republicans chance take pay back teapubl...\n",
       "6952     lincoln #firefighter dies #exercising #soundtr...\n",
       "Name: tweet, Length: 9589, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d19b2101",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "# Create a tokenizer pattern that preserves hashtags\n",
    "tokenizer = RegexpTokenizer(r'\\w+|#\\w+')\n",
    "\n",
    "# Tokenize X_train\n",
    "X_train_tokens = X_train_cleaned.apply(tokenizer.tokenize)\n",
    "\n",
    "# Tokenize X_test\n",
    "X_test_tokens = X_test_cleaned.apply(tokenizer.tokenize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6560d9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "# Apply stemming to X_train_tokens\n",
    "X_train_stemmed = X_train_tokens.apply(lambda x: [stemmer.stem(word) for word in x])\n",
    "\n",
    "# Apply stemming to X_test_tokens\n",
    "X_test_stemmed = X_test_tokens.apply(lambda x: [stemmer.stem(word) for word in x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b09927fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12227    [mom, say, smile, captiv, say, happi, sunday, ...\n",
       "14709    [day, meet, si, law, couney, bower, first, vel...\n",
       "19319    [hate, conserv, homophob, use, tragedi, way, s...\n",
       "4308     [awe, #scream, #friday, #acewellstuck, #cynthi...\n",
       "24055    [fathersday, #father, #day, #god, #toni, #smit...\n",
       "                               ...                        \n",
       "20593                           [#model, love, take, time]\n",
       "11682    [afraid, done, noth, wrong, salla, pura, barba...\n",
       "10882    [week, till, perform, showcas, #actor, #perfor...\n",
       "6084     [real, #republican, chanc, take, pay, back, te...\n",
       "6952     [lincoln, #firefight, die, #exercis, #soundtra...\n",
       "Name: tweet, Length: 9589, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e8763d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train_features: (22373, 24981)\n",
      "Shape of X_test_features: (9589, 24981)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize the TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit the vectorizer on the training data and transform the text into TF-IDF features\n",
    "X_train_features = vectorizer.fit_transform(X_train_stemmed.apply(lambda x: ' '.join(x)))\n",
    "\n",
    "# Transform the test data into TF-IDF features\n",
    "X_test_features = vectorizer.transform(X_test_stemmed.apply(lambda x: ' '.join(x)))\n",
    "\n",
    "# Print the shape of the feature matrices\n",
    "print(\"Shape of X_train_features:\", X_train_features.shape)\n",
    "print(\"Shape of X_test_features:\", X_test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7dca1d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8294a454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Xtrain_features: (22373, 24981)\n",
      "Shape of Xtest_features: (9589, 24981)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "#initialize the count vectorizer\n",
    "vectorizer2 = CountVectorizer()\n",
    "\n",
    "# Fit the vectorizer on the training data and transform the text into count features\n",
    "Xtrain_features = vectorizer2.fit_transform(X_train_stemmed.apply(lambda x: ' '.join(x)))\n",
    "\n",
    "# Transform the test data into count features\n",
    "Xtest_features = vectorizer2.transform(X_test_stemmed.apply(lambda x: ' '.join(x)))\n",
    "\n",
    "# Print the shape of the feature matrices\n",
    "print(\"Shape of Xtrain_features:\", Xtrain_features.shape)\n",
    "print(\"Shape of Xtest_features:\", Xtest_features.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c1d276a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy: 0.9394097403274585\n",
      "SVM Accuracy: 0.9553655229950986\n",
      "Logistic Regression Accuracy: 0.9463969131296277\n",
      "Random Forest Accuracy: 0.9587026801543436\n"
     ]
    }
   ],
   "source": [
    "#MODEL SELECTION WITH TF-IDF CLASSIFIER \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Create Naive Bayes classifier\n",
    "nb_classifier = MultinomialNB()\n",
    "nb_classifier.fit(X_train_features, y_train)\n",
    "nb_predictions = nb_classifier.predict(X_test_features)\n",
    "\n",
    "# Create SVM classifier\n",
    "svm_classifier = SVC()\n",
    "svm_classifier.fit(X_train_features, y_train)\n",
    "svm_predictions = svm_classifier.predict(X_test_features)\n",
    "\n",
    "# Create logistic regression classifier\n",
    "lr_classifier = LogisticRegression()\n",
    "lr_classifier.fit(X_train_features, y_train)\n",
    "lr_predictions = lr_classifier.predict(X_test_features)\n",
    "\n",
    "# Create random forest classifier\n",
    "rf_classifier = RandomForestClassifier()\n",
    "rf_classifier.fit(X_train_features, y_train)\n",
    "rf_predictions = rf_classifier.predict(X_test_features)\n",
    "\n",
    "# Evaluate the performance of each classifier\n",
    "nb_accuracy = accuracy_score(y_test, nb_predictions)\n",
    "svm_accuracy = accuracy_score(y_test, svm_predictions)\n",
    "lr_accuracy = accuracy_score(y_test, lr_predictions)\n",
    "rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
    "\n",
    "print(\"Naive Bayes Accuracy:\", nb_accuracy)\n",
    "print(\"SVM Accuracy:\", svm_accuracy)\n",
    "print(\"Logistic Regression Accuracy:\", lr_accuracy)\n",
    "print(\"Random Forest Accuracy:\", rf_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e77e5d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes F1 Score: 0.26175349428208383\n",
      "SVM F1 Score: 0.5694164989939638\n",
      "Logistic Regression F1 Score: 0.43392070484581496\n",
      "Random Forest F1 Score: 0.6373626373626374\n"
     ]
    }
   ],
   "source": [
    "#F-1 SCORE WITH TF-IDF\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Calculate the F1 score for Naive Bayes\n",
    "nb_f1_score = f1_score(y_test, nb_predictions)\n",
    "\n",
    "# Calculate the F1 score for SVM\n",
    "svm_f1_score = f1_score(y_test, svm_predictions)\n",
    "\n",
    "# Calculate the F1 score for Logistic Regression\n",
    "lr_f1_score = f1_score(y_test, lr_predictions)\n",
    "\n",
    "# Calculate the F1 score for Random Forest\n",
    "rf_f1_score = f1_score(y_test, rf_predictions)\n",
    "\n",
    "print(\"Naive Bayes F1 Score:\", nb_f1_score)\n",
    "print(\"SVM F1 Score:\", svm_f1_score)\n",
    "print(\"Logistic Regression F1 Score:\", lr_f1_score)\n",
    "print(\"Random Forest F1 Score:\", rf_f1_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "60f1d2c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy: 0.9574512462196266\n",
      "SVM Accuracy: 0.9547398060277401\n",
      "Logistic Regression Accuracy: 0.9564083846073625\n",
      "Random Forest Accuracy: 0.9576598185420795\n"
     ]
    }
   ],
   "source": [
    "#MODEL SELECTION WITH COUNT VECTORIZER\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Create Naive Bayes classifier\n",
    "nb_classifier2 = MultinomialNB()\n",
    "nb_classifier2.fit(Xtrain_features, y_train)\n",
    "nb_predictions2 = nb_classifier2.predict(Xtest_features)\n",
    "\n",
    "# Create SVM classifier\n",
    "svm_classifier2 = SVC()\n",
    "svm_classifier2.fit(Xtrain_features, y_train)\n",
    "svm_predictions2 = svm_classifier2.predict(Xtest_features)\n",
    "\n",
    "# Create logistic regression classifier\n",
    "lr_classifier2 = LogisticRegression()\n",
    "lr_classifier2.fit(Xtrain_features, y_train)\n",
    "lr_predictions2 = lr_classifier2.predict(Xtest_features)\n",
    "\n",
    "# Create random forest classifier\n",
    "rf_classifier2 = RandomForestClassifier()\n",
    "rf_classifier2.fit(Xtrain_features, y_train)\n",
    "rf_predictions2 = rf_classifier2.predict(Xtest_features)\n",
    "\n",
    "# Evaluate the performance of each classifier\n",
    "nb_accuracy2 = accuracy_score(y_test, nb_predictions2)\n",
    "svm_accuracy2 = accuracy_score(y_test, svm_predictions2)\n",
    "lr_accuracy2 = accuracy_score(y_test, lr_predictions2)\n",
    "rf_accuracy2 = accuracy_score(y_test, rf_predictions2)\n",
    "\n",
    "print(\"Naive Bayes Accuracy:\", nb_accuracy2)\n",
    "print(\"SVM Accuracy:\", svm_accuracy2)\n",
    "print(\"Logistic Regression Accuracy:\", lr_accuracy2)\n",
    "print(\"Random Forest Accuracy:\", rf_accuracy2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a548f059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes F1 Score: 0.6236162361623616\n",
      "SVM F1 Score: 0.5633802816901409\n",
      "Logistic Regression F1 Score: 0.6186131386861313\n",
      "Random Forest F1 Score: 0.6268382352941176\n"
     ]
    }
   ],
   "source": [
    "#F-1 SCORE WITH COUNT VECTORIZER\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Calculate the F1 score for Naive Bayes\n",
    "nb_f1_score2 = f1_score(y_test, nb_predictions2)\n",
    "\n",
    "# Calculate the F1 score for SVM\n",
    "svm_f1_score2 = f1_score(y_test, svm_predictions2)\n",
    "\n",
    "# Calculate the F1 score for Logistic Regression\n",
    "lr_f1_score2 = f1_score(y_test, lr_predictions2)\n",
    "\n",
    "# Calculate the F1 score for Random Forest\n",
    "rf_f1_score2 = f1_score(y_test, rf_predictions2)\n",
    "\n",
    "print(\"Naive Bayes F1 Score:\", nb_f1_score2)\n",
    "print(\"SVM F1 Score:\", svm_f1_score2)\n",
    "print(\"Logistic Regression F1 Score:\", lr_f1_score2)\n",
    "print(\"Random Forest F1 Score:\", rf_f1_score2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c7ab5b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decided to use Random Forest with TF-IDF to build the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "18577a3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31963</td>\n",
       "      <td>#studiolife #aislife #requires #passion #dedic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31964</td>\n",
       "      <td>@user #white #supremacists want everyone to s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31965</td>\n",
       "      <td>safe ways to heal your #acne!!    #altwaystohe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31966</td>\n",
       "      <td>is the hp and the cursed child book up for res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31967</td>\n",
       "      <td>3rd #bihday to my amazing, hilarious #nephew...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17192</th>\n",
       "      <td>49155</td>\n",
       "      <td>thought factory: left-right polarisation! #tru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17193</th>\n",
       "      <td>49156</td>\n",
       "      <td>feeling like a mermaid ð #hairflip #neverre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17194</th>\n",
       "      <td>49157</td>\n",
       "      <td>#hillary #campaigned today in #ohio((omg)) &amp;am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17195</th>\n",
       "      <td>49158</td>\n",
       "      <td>happy, at work conference: right mindset leads...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17196</th>\n",
       "      <td>49159</td>\n",
       "      <td>my   song \"so glad\" free download!  #shoegaze ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17197 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                              tweet\n",
       "0      31963  #studiolife #aislife #requires #passion #dedic...\n",
       "1      31964   @user #white #supremacists want everyone to s...\n",
       "2      31965  safe ways to heal your #acne!!    #altwaystohe...\n",
       "3      31966  is the hp and the cursed child book up for res...\n",
       "4      31967    3rd #bihday to my amazing, hilarious #nephew...\n",
       "...      ...                                                ...\n",
       "17192  49155  thought factory: left-right polarisation! #tru...\n",
       "17193  49156  feeling like a mermaid ð #hairflip #neverre...\n",
       "17194  49157  #hillary #campaigned today in #ohio((omg)) &am...\n",
       "17195  49158  happy, at work conference: right mindset leads...\n",
       "17196  49159  my   song \"so glad\" free download!  #shoegaze ...\n",
       "\n",
       "[17197 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv('test_tweets_anuFYb8.csv')\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5f49f791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        #studiolife #aislife #requires #passion #dedic...\n",
       "1           #white #supremacists want everyone to see t...\n",
       "2        safe ways to heal your #acne      #altwaystohe...\n",
       "3        is the hp and the cursed child book up for res...\n",
       "4           rd #bihday to my amazing  hilarious #nephew...\n",
       "                               ...                        \n",
       "17192    thought factory  left right polarisation  #tru...\n",
       "17193    feeling like a mermaid      #hairflip #neverre...\n",
       "17194    #hillary #campaigned today in #ohio  omg    am...\n",
       "17195    happy  at work conference  right mindset leads...\n",
       "17196    my   song  so glad  free download   #shoegaze ...\n",
       "Name: tweet, Length: 17197, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove special characters that are not # and a-z\n",
    "test_data['tweet'] = test_data['tweet'].str.replace('[^a-zA-Z#]', ' ', regex=True)\n",
    "\n",
    "#remove user \n",
    "test_data['tweet']= test_data['tweet'].str.replace('user','')\n",
    "\n",
    "test_data['tweet']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "af1d27ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        #studiolife #aislife #requires #passion #dedic...\n",
       "1        #white #supremacists want everyone see the new...\n",
       "2        safe ways heal your #acne #altwaystoheal #heal...\n",
       "3        the and the cursed child book for reservations...\n",
       "4        #bihday amazing hilarious #nephew eli ahmir un...\n",
       "                               ...                        \n",
       "17192    thought factory left right polarisation #trump...\n",
       "17193    feeling like mermaid #hairflip #neverready #fo...\n",
       "17194    #hillary #campaigned today #ohio omg amp used ...\n",
       "17195    happy work conference right mindset leads cult...\n",
       "17196    song glad free download #shoegaze #newmusic #n...\n",
       "Name: tweet, Length: 17197, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove additional spaces \n",
    "test_data['tweet'] = test_data['tweet'].apply(lambda x: re.sub(r'\\s+', ' ', x))\n",
    "\n",
    "#remove words that are less than 3 in length\n",
    "test_data['tweet'] = test_data['tweet'].apply(lambda x: ' '.join([word for word in x.split() if len(word) >= 3]))\n",
    "\n",
    "#convert all words to lowercase\n",
    "test_data['tweet'] = test_data['tweet'].str.lower()\n",
    "test_data['tweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6a4f8174",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "# Apply stopword removal to tweet column\n",
    "test_data['tweet_cleaned'] = test_data['tweet'].apply(lambda x: ' '.join(word for word in x.split() if word.lower() not in stop_words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e8765869",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop the initial tweet column \n",
    "test_data = test_data.drop('tweet',axis = 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d543e9d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31963</td>\n",
       "      <td>#studiolife #aislife #requires #passion #dedic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31964</td>\n",
       "      <td>#white #supremacists want everyone see new #bi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31965</td>\n",
       "      <td>safe ways heal #acne #altwaystoheal #healthy #...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31966</td>\n",
       "      <td>cursed child book reservations already yes #ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31967</td>\n",
       "      <td>#bihday amazing hilarious #nephew eli ahmir un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17192</th>\n",
       "      <td>49155</td>\n",
       "      <td>thought factory left right polarisation #trump...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17193</th>\n",
       "      <td>49156</td>\n",
       "      <td>feeling like mermaid #hairflip #neverready #fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17194</th>\n",
       "      <td>49157</td>\n",
       "      <td>#hillary #campaigned today #ohio omg amp used ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17195</th>\n",
       "      <td>49158</td>\n",
       "      <td>happy work conference right mindset leads cult...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17196</th>\n",
       "      <td>49159</td>\n",
       "      <td>song glad free download #shoegaze #newmusic #n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17197 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                      tweet_cleaned\n",
       "0      31963  #studiolife #aislife #requires #passion #dedic...\n",
       "1      31964  #white #supremacists want everyone see new #bi...\n",
       "2      31965  safe ways heal #acne #altwaystoheal #healthy #...\n",
       "3      31966  cursed child book reservations already yes #ha...\n",
       "4      31967  #bihday amazing hilarious #nephew eli ahmir un...\n",
       "...      ...                                                ...\n",
       "17192  49155  thought factory left right polarisation #trump...\n",
       "17193  49156  feeling like mermaid #hairflip #neverready #fo...\n",
       "17194  49157  #hillary #campaigned today #ohio omg amp used ...\n",
       "17195  49158  happy work conference right mindset leads cult...\n",
       "17196  49159  song glad free download #shoegaze #newmusic #n...\n",
       "\n",
       "[17197 rows x 2 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f978e02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "# Create a tokenizer pattern that preserves hashtags\n",
    "tokenizer = RegexpTokenizer(r'\\w+|#\\w+')\n",
    "\n",
    "# Tokenize tweet cleaned column\n",
    "tweet_cleaned_tokens = test_data['tweet_cleaned'].apply(tokenizer.tokenize)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3978b1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "# Apply stemming to tweet cleaned column\n",
    "tweet_cleaned_stemmed = tweet_cleaned_tokens.apply(lambda x: [stemmer.stem(word) for word in x])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5f05f728",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize the TF-IDF vectorizer\n",
    "new_vectorizer = TfidfVectorizer(vocabulary=vocabulary)\n",
    "\n",
    "# Fit the vectorizer on the column and transform the text into TF-IDF features\n",
    "vectorised_tweet_cleaned = new_vectorizer.fit_transform(tweet_cleaned_stemmed.apply(lambda x: ' '.join(x)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "820da7e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<17197x24981 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 110582 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorised_tweet_cleaned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "95ac64e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = rf_classifier.predict(vectorised_tweet_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ed23b9ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet_cleaned</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31963</td>\n",
       "      <td>#studiolife #aislife #requires #passion #dedic...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31964</td>\n",
       "      <td>#white #supremacists want everyone see new #bi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31965</td>\n",
       "      <td>safe ways heal #acne #altwaystoheal #healthy #...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31966</td>\n",
       "      <td>cursed child book reservations already yes #ha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31967</td>\n",
       "      <td>#bihday amazing hilarious #nephew eli ahmir un...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17192</th>\n",
       "      <td>49155</td>\n",
       "      <td>thought factory left right polarisation #trump...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17193</th>\n",
       "      <td>49156</td>\n",
       "      <td>feeling like mermaid #hairflip #neverready #fo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17194</th>\n",
       "      <td>49157</td>\n",
       "      <td>#hillary #campaigned today #ohio omg amp used ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17195</th>\n",
       "      <td>49158</td>\n",
       "      <td>happy work conference right mindset leads cult...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17196</th>\n",
       "      <td>49159</td>\n",
       "      <td>song glad free download #shoegaze #newmusic #n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17197 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                      tweet_cleaned  \\\n",
       "0      31963  #studiolife #aislife #requires #passion #dedic...   \n",
       "1      31964  #white #supremacists want everyone see new #bi...   \n",
       "2      31965  safe ways heal #acne #altwaystoheal #healthy #...   \n",
       "3      31966  cursed child book reservations already yes #ha...   \n",
       "4      31967  #bihday amazing hilarious #nephew eli ahmir un...   \n",
       "...      ...                                                ...   \n",
       "17192  49155  thought factory left right polarisation #trump...   \n",
       "17193  49156  feeling like mermaid #hairflip #neverready #fo...   \n",
       "17194  49157  #hillary #campaigned today #ohio omg amp used ...   \n",
       "17195  49158  happy work conference right mindset leads cult...   \n",
       "17196  49159  song glad free download #shoegaze #newmusic #n...   \n",
       "\n",
       "       predicted_label  \n",
       "0                    0  \n",
       "1                    1  \n",
       "2                    0  \n",
       "3                    0  \n",
       "4                    0  \n",
       "...                ...  \n",
       "17192                1  \n",
       "17193                0  \n",
       "17194                0  \n",
       "17195                0  \n",
       "17196                0  \n",
       "\n",
       "[17197 rows x 3 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_df = pd.DataFrame({'predicted_label':predictions})\n",
    "test_data_predicted = test_data.join(predictions_df)\n",
    "test_data_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4ccb349b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet_cleaned</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31964</td>\n",
       "      <td>#white #supremacists want everyone see new #bi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>31982</td>\n",
       "      <td>thought factory bbc neutrality right wing fasc...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>31989</td>\n",
       "      <td>chick gets fucked hottest naked lady</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>31996</td>\n",
       "      <td>suppo #taiji fisherman bullying racism #tweet ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>32073</td>\n",
       "      <td>hey ivanka bracelet feel good profiting #xenop...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17125</th>\n",
       "      <td>49088</td>\n",
       "      <td>careful criticizing #obama decision #israel am...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17128</th>\n",
       "      <td>49091</td>\n",
       "      <td>government new #anti semitism definition confl...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17176</th>\n",
       "      <td>49139</td>\n",
       "      <td>racist pay ever</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17188</th>\n",
       "      <td>49151</td>\n",
       "      <td>black professor demonizes proposes nazi style ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17192</th>\n",
       "      <td>49155</td>\n",
       "      <td>thought factory left right polarisation #trump...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>759 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                      tweet_cleaned  \\\n",
       "1      31964  #white #supremacists want everyone see new #bi...   \n",
       "19     31982  thought factory bbc neutrality right wing fasc...   \n",
       "26     31989               chick gets fucked hottest naked lady   \n",
       "33     31996  suppo #taiji fisherman bullying racism #tweet ...   \n",
       "110    32073  hey ivanka bracelet feel good profiting #xenop...   \n",
       "...      ...                                                ...   \n",
       "17125  49088  careful criticizing #obama decision #israel am...   \n",
       "17128  49091  government new #anti semitism definition confl...   \n",
       "17176  49139                                    racist pay ever   \n",
       "17188  49151  black professor demonizes proposes nazi style ...   \n",
       "17192  49155  thought factory left right polarisation #trump...   \n",
       "\n",
       "       predicted_label  \n",
       "1                    1  \n",
       "19                   1  \n",
       "26                   1  \n",
       "33                   1  \n",
       "110                  1  \n",
       "...                ...  \n",
       "17125                1  \n",
       "17128                1  \n",
       "17176                1  \n",
       "17188                1  \n",
       "17192                1  \n",
       "\n",
       "[759 rows x 3 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_predicted.loc[test_data_predicted['predicted_label']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cbfda44f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet_cleaned</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31963</td>\n",
       "      <td>#studiolife #aislife #requires #passion #dedic...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31965</td>\n",
       "      <td>safe ways heal #acne #altwaystoheal #healthy #...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31966</td>\n",
       "      <td>cursed child book reservations already yes #ha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31967</td>\n",
       "      <td>#bihday amazing hilarious #nephew eli ahmir un...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>31968</td>\n",
       "      <td>choose #momtips</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17191</th>\n",
       "      <td>49154</td>\n",
       "      <td>damn tuff ruff muff techno city web ukhx int #...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17193</th>\n",
       "      <td>49156</td>\n",
       "      <td>feeling like mermaid #hairflip #neverready #fo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17194</th>\n",
       "      <td>49157</td>\n",
       "      <td>#hillary #campaigned today #ohio omg amp used ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17195</th>\n",
       "      <td>49158</td>\n",
       "      <td>happy work conference right mindset leads cult...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17196</th>\n",
       "      <td>49159</td>\n",
       "      <td>song glad free download #shoegaze #newmusic #n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16438 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                      tweet_cleaned  \\\n",
       "0      31963  #studiolife #aislife #requires #passion #dedic...   \n",
       "2      31965  safe ways heal #acne #altwaystoheal #healthy #...   \n",
       "3      31966  cursed child book reservations already yes #ha...   \n",
       "4      31967  #bihday amazing hilarious #nephew eli ahmir un...   \n",
       "5      31968                                    choose #momtips   \n",
       "...      ...                                                ...   \n",
       "17191  49154  damn tuff ruff muff techno city web ukhx int #...   \n",
       "17193  49156  feeling like mermaid #hairflip #neverready #fo...   \n",
       "17194  49157  #hillary #campaigned today #ohio omg amp used ...   \n",
       "17195  49158  happy work conference right mindset leads cult...   \n",
       "17196  49159  song glad free download #shoegaze #newmusic #n...   \n",
       "\n",
       "       predicted_label  \n",
       "0                    0  \n",
       "2                    0  \n",
       "3                    0  \n",
       "4                    0  \n",
       "5                    0  \n",
       "...                ...  \n",
       "17191                0  \n",
       "17193                0  \n",
       "17194                0  \n",
       "17195                0  \n",
       "17196                0  \n",
       "\n",
       "[16438 rows x 3 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_predicted.loc[test_data_predicted['predicted_label']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c0bba8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
